{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d547b-0c67-4ddf-82f2-6a40193f975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c22c8e-a0c2-4982-871c-f299836cf6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab9a0f-078f-4c3e-ac22-652522ab1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import __version__ as langchain_version\n",
    "import openai\n",
    "print(f\"LangChain version: {langchain_version}\")\n",
    "print(\"OpenAI library imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac200d38-e4f5-4e60-8b54-b4f676b89997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chains import SequentialChain, LLMChain, ConversationChain\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f88653-646f-4436-94da-b379fbfe7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(temperature=0.3, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00785753-9099-4f65-873a-349c53b37143",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498afd9-299d-4d26-a3b1-c29a26230514",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_tracking_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Check the status of order ID {order_id}. Provide expected delivery date and any delay updates.\"\n",
    ")\n",
    "\n",
    "product_inquiry_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Provide details about the product {product_name}, including specifications, pricing, and stock availability.\"\n",
    ")\n",
    "\n",
    "refund_policy_prompt = ChatPromptTemplate.from_template(\n",
    "    \"A customer wants to return an item. Based on their request: {return_request}, explain the return process and refund policy.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4510d1e-0481-40f9-95a1-32c715ad02a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_tracking_chain = LLMChain(llm=llm, prompt=order_tracking_prompt, output_key=\"order_status\")\n",
    "product_inquiry_chain = LLMChain(llm=llm, prompt=product_inquiry_prompt, output_key=\"product_info\")\n",
    "refund_policy_chain = LLMChain(llm=llm, prompt=refund_policy_prompt, output_key=\"refund_details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7467fc73-119e-4018-bbf4-662665f176ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_workflow = SequentialChain(\n",
    "    chains=[order_tracking_chain, product_inquiry_chain, refund_policy_chain],\n",
    "    input_variables=[\"order_id\", \"product_name\", \"return_request\"],\n",
    "    output_variables=[\"order_status\", \"product_info\", \"refund_details\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd43a9-185f-40dc-93fb-81d6c6ce358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationChain(llm=llm, memory=summary_memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae2366-c16b-447a-94cc-f2ef1cc6eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conversation_chain.invoke(\n",
    "    \"Hi, I ordered a PlayStation 5 with order ID ORD67890. It was supposed to arrive yesterday but hasn’t. Can you check the status?\"\n",
    "))\n",
    "\n",
    "print(conversation_chain.invoke(\n",
    "    \"Also, I’m interested in buying a gaming headset. What options do you have?\"\n",
    "))\n",
    "\n",
    "print(conversation_chain.invoke(\n",
    "    \"If I change my mind about the PlayStation 5, how can I return it, and how long does the refund take?\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e3fa1a-3554-45e5-beef-696b2cc5f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConversation Summary:\", summary_memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbcc633-96db-40c2-a778-e680438bd4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = combined_workflow.invoke({\n",
    "    \"order_id\": \"ORD67890\",\n",
    "    \"product_name\": \"Wireless Gaming Headset\",\n",
    "    \"return_request\": \"I want to return my PlayStation 5 because I changed my mind.\"\n",
    "})\n",
    "\n",
    "print(\"\\n Order Tracking Response:\", response[\"order_status\"])\n",
    "print(\"\\n Product Inquiry Response:\", response[\"product_info\"])\n",
    "print(\"\\n Refund Policy Response:\", response[\"refund_details\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
